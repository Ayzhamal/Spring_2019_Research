############################################################################
# Read in our training and testing data
library(data.table)
training <- read.csv('/home/ayzhamal/Documents/RStudio/TrainingSet40.csv',header = TRUE)
#training <- training[,names(training) != "DNA"] # use this line if you want to remove the 'name' of each row
#training <- training[sample(nrow(training), nrow(training)), ] #randomizes the rows
#training$class[training$class == "1"] <- "positive" # Assigns "Positive" to the 1 class
#training$class[training$class == "0"] <- "negative" # Assigns 'Negative' to the 0 class
training$class <- factor(training$class)
#Preparing testing data
testing = read.csv("/home/ayzhamal/Documents/RStudio/TestingSet8.csv", header = TRUE)
#testing <- testing[,names(testing) != "DNA"] # use this line if you want to remove the 'name' of each row
#testing <- testing[sample(nrow(testing), nrow(testing)), ] #randomizes the rows
#testing$class[testing$class == "1"] <- "positive" # Assigns "Positive" to the 1 class
#testing$class[testing$class == "0"] <- "negative" # Assigns 'Negative' to the 0 class
testing$class <- factor(testing$class)
#################################################################################
##############################################################################
# Libraries we need to use, majority use caret
suppressMessages(library(caret))
suppressMessages(library(e1071))
# #############################################################################
# #CARET Random Forest definition
do.RF <- function(training)
{
set.seed(313)
n <- dim(training)[2]
gridRF <- expand.grid(mtry = seq(from=0,by=as.integer(n/10),to=n)[-1]) #may need to change this depend on your data size
ctrl.crossRF <- trainControl(method = "cv",number = 5,classProbs = TRUE,savePredictions = TRUE,allowParallel=TRUE)
rf.Fit <- train(class ~ .,data = training,method = "rf",metric = "Accuracy",preProc = c("center", "scale"),
ntree = 200, tuneGrid = gridRF,trControl = ctrl.crossRF)
rf.Fit
}
#training and testing
rf.Fit <- do.RF(training) #training done here
print(rf.Fit)
Pred <-  predict(rf.Fit,testing)#prediction on the testing set
cm <- confusionMatrix(Pred,testing$class)
print("CM for RF:")
print(cm)
saveRDS(rf.Fit, "RF.Rds") #saves the model to an rds file
#############################################################################
install.packages("caret")
install.packages("caret")
install.packages("e1071")
############################################################################
# Read in our training and testing data
library(data.table)
training <- read.csv('/home/ayzhamal/Documents/RStudio/TrainingSet40.csv',header = TRUE)
#training <- training[,names(training) != "DNA"] # use this line if you want to remove the 'name' of each row
#training <- training[sample(nrow(training), nrow(training)), ] #randomizes the rows
#training$class[training$class == "1"] <- "positive" # Assigns "Positive" to the 1 class
#training$class[training$class == "0"] <- "negative" # Assigns 'Negative' to the 0 class
training$class <- factor(training$class)
#Preparing testing data
testing = read.csv("/home/ayzhamal/Documents/RStudio/TestingSet8.csv", header = TRUE)
#testing <- testing[,names(testing) != "DNA"] # use this line if you want to remove the 'name' of each row
#testing <- testing[sample(nrow(testing), nrow(testing)), ] #randomizes the rows
#testing$class[testing$class == "1"] <- "positive" # Assigns "Positive" to the 1 class
#testing$class[testing$class == "0"] <- "negative" # Assigns 'Negative' to the 0 class
testing$class <- factor(testing$class)
#################################################################################
##############################################################################
# Libraries we need to use, majority use caret
suppressMessages(library(caret))
suppressMessages(library(e1071))
# #############################################################################
# #CARET Random Forest definition
do.RF <- function(training)
{
set.seed(313)
n <- dim(training)[2]
gridRF <- expand.grid(mtry = seq(from=0,by=as.integer(n/10),to=n)[-1]) #may need to change this depend on your data size
ctrl.crossRF <- trainControl(method = "cv",number = 5,classProbs = TRUE,savePredictions = TRUE,allowParallel=TRUE)
rf.Fit <- train(class ~ .,data = training,method = "rf",metric = "Accuracy",preProc = c("center", "scale"),
ntree = 200, tuneGrid = gridRF,trControl = ctrl.crossRF)
rf.Fit
}
#training and testing
rf.Fit <- do.RF(training) #training done here
print(rf.Fit)
Pred <-  predict(rf.Fit,testing)#prediction on the testing set
cm <- confusionMatrix(Pred,testing$class)
print("CM for RF:")
print(cm)
saveRDS(rf.Fit, "RF.Rds") #saves the model to an rds file
#############################################################################
?saveRDS
setwd("/home/ayzhamal/Documents/GitHub/Spring_2019_Research/Output_RDS_files")
# Read in our training and testing data
library(data.table)
training <- read.csv("https://raw.githubusercontent.com/Ayzhamal/Spring_2019_Research/master/datasets/small_dataset/TrainingSet40.csv",header = TRUE)
training <- data.frame(training)
#training <- training[,names(training) != "DNA"] # use this line if you want to remove the 'name' of each row
training <- training[sample(nrow(training), nrow(training)), ] #randomizes the rows
training$class[training$class == "real"] <- "positive" # Assigns "Positive" to the real class
training$class[training$class == "random"] <- "negative" # Assigns 'Negative' to the random class
training$class <- factor(training$class)
#Preparing testing data
testing = read.csv("https://raw.githubusercontent.com/Ayzhamal/Spring_2019_Research/master/datasets/small_dataset/TestingSet8.csv", header = TRUE)
testing <- data.frame(testing)
#testing <- testing[,names(testing) != "DNA"] # use this line if you want to remove the 'name' of each row
testing <- testing[sample(nrow(testing), nrow(testing)), ] #randomizes the rows
testing$class[testing$class == "real"] <- "positive" # Assigns "Positive" to the real class
testing$class[testing$class == "random"] <- "negative" # Assigns 'Negative' to the random class
testing$class <- factor(testing$class)
testing <- data.frame(testing)
#################################################################################
View(training)
View(training)
View(training)
View(testing)
############################################################################
############################################################################
# Read in our training and testing data
library(data.table)
training <- read.csv("https://raw.githubusercontent.com/Ayzhamal/Spring_2019_Research/master/datasets/small_dataset/TrainingSet40.csv",header = TRUE)
training <- data.frame(training)
#training <- training[,names(training) != "DNA"] # use this line if you want to remove the 'name' of each row
training <- training[sample(nrow(training), nrow(training)), ] #randomizes the rows
#training$class[training$class == "real"] <- "positive" # Assigns "Positive" to the real class
#training$class[training$class == "random"] <- "negative" # Assigns 'Negative' to the random class
training$class <- factor(training$class)
#Preparing testing data
testing = read.csv("https://raw.githubusercontent.com/Ayzhamal/Spring_2019_Research/master/datasets/small_dataset/TestingSet8.csv", header = TRUE)
testing <- data.frame(testing)
#testing <- testing[,names(testing) != "DNA"] # use this line if you want to remove the 'name' of each row
testing <- testing[sample(nrow(testing), nrow(testing)), ] #randomizes the rows
#testing$class[testing$class == "real"] <- "positive" # Assigns "Positive" to the real class
#testing$class[testing$class == "random"] <- "negative" # Assigns 'Negative' to the random class
testing$class <- factor(testing$class)
testing <- data.frame(testing)
#######################################################
############################################################################
############################################################################
# Read in our training and testing data
library(data.table)
training <- read.csv("https://raw.githubusercontent.com/Ayzhamal/Spring_2019_Research/master/datasets/small_dataset/TrainingSet40.csv",header = TRUE)
training <- data.frame(training)
#training <- training[,names(training) != "DNA"] # use this line if you want to remove the 'name' of each row
training <- training[sample(nrow(training), nrow(training)), ] #randomizes the rows
#training$class[training$class == "real"] <- "positive" # Assigns "Positive" to the real class
#training$class[training$class == "random"] <- "negative" # Assigns 'Negative' to the random class
training$class <- factor(training$class)
#Preparing testing data
testing = read.csv("https://raw.githubusercontent.com/Ayzhamal/Spring_2019_Research/master/datasets/small_dataset/TestingSet8.csv", header = TRUE)
testing <- data.frame(testing)
#testing <- testing[,names(testing) != "DNA"] # use this line if you want to remove the 'name' of each row
testing <- testing[sample(nrow(testing), nrow(testing)), ] #randomizes the rows
#testing$class[testing$class == "real"] <- "positive" # Assigns "Positive" to the real class
#testing$class[testing$class == "random"] <- "negative" # Assigns 'Negative' to the random class
testing$class <- factor(testing$class)
testing <- data.frame(testing)
#######################################################
View(testing)
View(training)
##############################################################################
# Libraries we need to use, majority use caret
suppressMessages(library(caret))
suppressMessages(library(e1071))
# 1.CARET Random Forest definition
do.RF <- function(training)
{
set.seed(313)
n <- dim(training)[2]
gridRF <- expand.grid(mtry = seq(from=0,by=as.integer(n/40),to=n)[-1]) #may need to change this depend on your data size
ctrl.crossRF <- trainControl(method = "cv",number = 5,classProbs = TRUE,savePredictions = TRUE,allowParallel=TRUE)
rf.Fit <- train(class ~ .,data = training,method = "rf",metric = "Accuracy",preProc = c("center", "scale"),
ntree = 200, tuneGrid = gridRF,trControl = ctrl.crossRF)
rf.Fit
}
#training and testing
rf.Fit <- do.RF(training) #training done here
View(rf.Fit)
rf.Fit
rf.Fit
Pred <-  predict(rf.Fit, testing, type="prob") #prediction on the testing set
cm <- confusionMatrix(Pred, testing$class) # will show accuracy, sensitivity, specifity
print("CM for RF: Sensitivity...:")
print(cm)
cm <- confusionMatrix(Pred, testing$class, mode = "prec_recall") # will show Precision, Recall, F1 Score
View(training)
View(testing)
print("CM for RF: Recall...")
print(cm)
result.roc <- plot(roc(testing$class, Pred$real))
install.packages("pROC")
library('pROC')
result.roc <- plot(roc(testing$class, Pred$real))
plot(result.roc, print.thres="best", print.thres.best.method="closest.topleft")
auc(result.roc)
saveRDS(rf.Fit, "RF.Rds") #saves the model to an rds file
#############################################################################
# 2.CARET boosted trees definition
do.Boost <- function(training)
{
#trials = number of boosting iterations, or (simply number of trees)
#winnow = remove unimportant predictors
gridBoost <- expand.grid(model="tree",trials=seq(from=1,by=2,to=100),winnow=FALSE)
set.seed(1)
ctrl.crossBoost <- trainControl(method = "cv",number = 10,classProbs = TRUE,savePredictions = TRUE,allowParallel=TRUE)
C5.0.Fit <- train(class ~ .,data = training,method = "C5.0",metric = "Accuracy",preProc = c("center", "scale"),
tuneGrid = gridBoost,trControl = ctrl.crossBoost)
C5.0.Fit
}
View(result.roc)
View(Pred)
RF <- readRDS("~/Documents/GitHub/Spring_2019_Research/Output_RDS_files/RF.Rds")
View(RF)
#############################################################################
# 2.CARET boosted trees definition
do.Boost <- function(training)
{
#trials = number of boosting iterations, or (simply number of trees)
#winnow = remove unimportant predictors
gridBoost <- expand.grid(model="tree",trials=seq(from=1,by=2,to=100),winnow=FALSE)
set.seed(1)
ctrl.crossBoost <- trainControl(method = "cv",number = 5,classProbs = TRUE,savePredictions = TRUE,allowParallel=TRUE)
C5.0.Fit <- train(class ~ .,data = training,method = "C5.0",metric = "Accuracy",preProc = c("center", "scale"),
tuneGrid = gridBoost,trControl = ctrl.crossBoost)
C5.0.Fit
}
#training
boost.Fit <- do.Boost(training)
Pred <-  predict(boost.Fit,testing) #prediction on the testing set
cm <- confusionMatrix(Pred,testing$class)
print("CM for Boosted: Sensitivity...")
print(cm)
cm <- confusionMatrix(Pred, testing$class, mode = "prec_recall") # will show Precision, Recall, F1 Score
print("CM for Boosted: Recall...")
print(cm)
saveRDS(boost.Fit, "Boost.rds") #saves the model to an rds file
#install.packages("pROC")
library(pROC)
Pred <-  predict(boost.Fit, testing, type = "prob")
#Pred <-  predict(boost.Fit, testing, type = "prob")
result.roc <- plot(roc(testing$class, Pred$real))
plot(result.roc, print.thres="best", print.thres.best.method="closest.topleft")
auc(result.roc)
RP.perf <- performance(Pred, "prec", "rec");
install.packages("prec", "rec")
install.packages("prec")
install.packages("pREC")
install.packages("rec")
################################################################################
#3. Regularization elastic-net logistic regression:
install.packages("glmnet", repos = "http://cran.us.r-project.org", dependencies = TRUE)
library(glmnet)
traintest=rbind(training,testing)
X = sparse.model.matrix(as.formula(paste("class ~", paste(colnames(training[,-1]), sep = "", collapse=" +"))), data = traintest)
#Alpha - 0.5
logreg.fit05 = cv.glmnet(X[1:nrow(training),], training[,1], alpha = 0.5, family = "binomial",type.measure = "auc",nfolds = 10)
#Alpha - 0.5
logreg.fit05 = cv.glmnet(X[1:nrow(training),], training[,1], alpha = 0.5, family = "binomial",type.measure = "auc",nfolds = 5)
plot(logreg.fit05)
model$lambda.min
#predict on test set
pred05 = predict(model, s='lambda.min', newx=X[-(1:nrow(training)),], type="class")
cm05 <- confusionMatrix(factor(pred05),factor(testing$class))
#predict on test set
pred05 = predict(model, s='lambda.min', newx=X[-(1:nrow(training)),], type="class")
